{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFJZTttlQcJ_"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VESCmNeiRe77"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOMWeFL3Bqx2"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "  \"\"\"Function to load the dataset\"\"\"\n",
        "  with open('shakespeare-2.txt', mode='r', encoding='utf-8') as f:\n",
        "    data = f.read() #data is a string that contains the text file\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "OYPxdnc8EuOg",
        "outputId": "c0bdb206-74a3-47ba-b42e-a8e68f405f22"
      },
      "outputs": [],
      "source": [
        "data = load_data()\n",
        "words = data.split()\n",
        "distinct_words = sorted(list(set(words))) # vocabulary\n",
        "word_to_idx = dict((word, i) for i, word in enumerate(distinct_words)) #each word has an index\n",
        "idx_to_word = dict((i, word) for i, word in enumerate(distinct_words)) #each index has a word. useful for text generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1MgZw98GmvK"
      },
      "outputs": [],
      "source": [
        "# Define constants\n",
        "N_seq = 50 # Length of the input sequence to be fed\n",
        "N_words = len(words)\n",
        "N_vocab = len(distinct_words)\n",
        "print(N_data, N_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "Z7r5_KljN2ha",
        "outputId": "8478570f-833b-47e0-c899-6ad1c9a107f7"
      },
      "outputs": [],
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "for i in range(0, N_words - N_seq, 1):\n",
        "  # Given x of 100 charcters (Input Sequence), predict the next character y (Conditional Probability)\n",
        "\tx = words[i:i+N_seq]\n",
        "\ty = words[i+N_seq]\n",
        "\tx_train.append([word_to_idx[x_i] for x_i in x])\n",
        "\ty_train.append(word_to_idx[y])\n",
        "\n",
        "m = len(x_train)\n",
        "assert m == len(y_train), \"Length mismatch error\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPQkosyvnwrL"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# One-hot-encoding the input data\n",
        "for i in range(m):\n",
        "  x_train[i] = to_categorical(x_train[i], num_classes=N_vocab)\n",
        "\n",
        "# One-hot-coding the output values\n",
        "y_train = to_categorical(y_train, num_classes=N_vocab)\n",
        "\n",
        "# Reshaping x_train to be [samples, timesteps, features]\n",
        "x_train = np.array(x_train).reshape(m, N_seq, N_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XAOe83ORa7F"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlrnOhJGRE2n"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "\n",
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(512, input_shape=x_train[0].shape, return_sequences=True))\n",
        "  model.add(LSTM(512, return_sequences=True))\n",
        "  model.add(LSTM(512))\n",
        "  model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BuTjQHeSdGS"
      },
      "outputs": [],
      "source": [
        "model = build_model()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DeELtmpcRGMW",
        "outputId": "c90ef2c8-fc7a-41bf-d443-91507fe6755d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "99943/99943 [==============================] - 386s 4ms/step - loss: 2.9471\n",
            "Epoch 2/30\n",
            "99943/99943 [==============================] - 382s 4ms/step - loss: 2.6915\n",
            "Epoch 3/30\n",
            "99943/99943 [==============================] - 382s 4ms/step - loss: 2.1866\n",
            "Epoch 4/30\n",
            "99943/99943 [==============================] - 381s 4ms/step - loss: 2.0075\n",
            "Epoch 5/30\n",
            "99943/99943 [==============================] - 383s 4ms/step - loss: 1.8720\n",
            "Epoch 6/30\n",
            "99943/99943 [==============================] - 382s 4ms/step - loss: 1.7658\n",
            "Epoch 7/30\n",
            "99943/99943 [==============================] - 384s 4ms/step - loss: 1.6693\n",
            "Epoch 8/30\n",
            "99943/99943 [==============================] - 385s 4ms/step - loss: 1.5929\n",
            "Epoch 9/30\n",
            "99943/99943 [==============================] - 385s 4ms/step - loss: 1.5241\n",
            "Epoch 10/30\n",
            "99943/99943 [==============================] - 387s 4ms/step - loss: 1.4610\n",
            "Epoch 11/30\n",
            "99943/99943 [==============================] - 384s 4ms/step - loss: 1.3991\n",
            "Epoch 12/30\n",
            "99943/99943 [==============================] - 386s 4ms/step - loss: 1.3428\n",
            "Epoch 13/30\n",
            "99943/99943 [==============================] - 384s 4ms/step - loss: 1.2918\n",
            "Epoch 14/30\n",
            "99943/99943 [==============================] - 384s 4ms/step - loss: 1.2343\n",
            "Epoch 15/30\n",
            "99943/99943 [==============================] - 384s 4ms/step - loss: 1.1786\n",
            "Epoch 16/30\n",
            "99943/99943 [==============================] - 385s 4ms/step - loss: 1.1204\n",
            "Epoch 17/30\n",
            "99943/99943 [==============================] - 383s 4ms/step - loss: 1.0597\n",
            "Epoch 18/30\n",
            "99943/99943 [==============================] - 384s 4ms/step - loss: 0.9999\n",
            "Epoch 19/30\n",
            "99943/99943 [==============================] - 384s 4ms/step - loss: 0.9388\n",
            "Epoch 20/30\n",
            "99943/99943 [==============================] - 386s 4ms/step - loss: 0.8728\n",
            "Epoch 21/30\n",
            "99943/99943 [==============================] - 385s 4ms/step - loss: 0.8052\n",
            "Epoch 22/30\n",
            "99943/99943 [==============================] - 386s 4ms/step - loss: 0.7397\n",
            "Epoch 23/30\n",
            "99943/99943 [==============================] - 386s 4ms/step - loss: 0.6678\n",
            "Epoch 24/30\n",
            "99943/99943 [==============================] - 386s 4ms/step - loss: 0.6000\n",
            "Epoch 25/30\n",
            "99943/99943 [==============================] - 387s 4ms/step - loss: 0.5311\n",
            "Epoch 26/30\n",
            "99943/99943 [==============================] - 389s 4ms/step - loss: 0.4670\n",
            "Epoch 27/30\n",
            "99943/99943 [==============================] - 389s 4ms/step - loss: 0.4048\n",
            "Epoch 28/30\n",
            "99943/99943 [==============================] - 386s 4ms/step - loss: 0.3459\n",
            "Epoch 29/30\n",
            "99943/99943 [==============================] - 385s 4ms/step - loss: 0.2929\n",
            "Epoch 30/30\n",
            "99943/99943 [==============================] - 387s 4ms/step - loss: 0.2506\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Callbacks:\n",
        "PATH_SAVE = \"shakespearean_generator_2.h5\"\n",
        "checkpoint = ModelCheckpoint(PATH_SAVE, monitor='loss', mode='min')\n",
        "cb_list = [checkpoint]\n",
        "\n",
        "# Fitting\n",
        "history = model.fit(x_train, y_train, epochs=30, batch_size=128, callbacks=cb_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IUKqwPMksoY"
      },
      "source": [
        "## Generating Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_HCLQZap_cH"
      },
      "outputs": [],
      "source": [
        "def generate(seed_words, ohed_seed, N_words):\n",
        "    \"\"\"\n",
        "    seed_words: list of initial words (strings)\n",
        "    ohed_seed: list of one-hot encoded vectors of those seed words\n",
        "    N_words: number of new words to generate\n",
        "    \"\"\"\n",
        "    x0 = ohed_seed.copy()\n",
        "    generated_indices = [word_to_idx[word] for word in seed_words]\n",
        "\n",
        "    for _ in range(N_words):\n",
        "        x = np.array(x0).reshape(1, N_seq, N_vocab)\n",
        "        probabilities = model.predict(x, verbose=0)  # predict next word\n",
        "        idx = np.random.choice(N_vocab, p=probabilities.ravel())  # sample word index\n",
        "        ohed_idx = to_categorical(idx, num_classes=N_vocab)  # OHE of that index\n",
        "        x0.append(ohed_idx)\n",
        "        generated_indices.append(idx)\n",
        "        x0 = x0[1:]  # slide window\n",
        "\n",
        "    # Convert indices back to words\n",
        "    generated_words = [idx_to_word[i] for i in generated_indices]\n",
        "    return ' '.join(generated_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "W11086BnqUAF",
        "outputId": "d3fd4516-378e-4f15-a2f0-298f94b94fa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The initial word is :                            YOUR AWESOME CHARACTER:\n"
          ]
        }
      ],
      "source": [
        "initial_seed = \"your awesome character is very powerful today\".lower()\n",
        "seed_words = initial_seed.split()\n",
        "\n",
        "# Ensure all words are in the vocabulary\n",
        "words_input = set(seed_words)\n",
        "words_valid = set(word_to_idx.keys())\n",
        "invalid_words = words_input.difference(words_valid)\n",
        "if invalid_words:\n",
        "    raise SyntaxError(f\"Input contains invalid words: {invalid_words}\")\n",
        "\n",
        "# Truncate long sequences\n",
        "if len(seed_words) > N_seq:\n",
        "    seed_words = seed_words[-N_seq:]  # keep the last N_seq words\n",
        "\n",
        "# Pad short sequences with a special token or just ' ' (space)\n",
        "N_pad = max(N_seq - len(seed_words), 0)\n",
        "seed_words = ['<PAD>'] * N_pad + seed_words\n",
        "\n",
        "print(\"The seed words are:\", seed_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7EwOde3YOtv"
      },
      "outputs": [],
      "source": [
        "seed = [word_to_idx[word] for word in seed_words]\n",
        "ohed_seed = [to_categorical(idx, num_classes=N_vocab) for idx in seed]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFJibll6YMJV"
      },
      "outputs": [],
      "source": [
        "generated_sentence = generate(seed, ohed_seed, 500)[N_pad:] # Remove the prepended padding, if any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "rb0_yaGbcJiW",
        "outputId": "88a92540-1df9-4342-fe97-ac991cd405d4"
      },
      "outputs": [],
      "source": [
        "generated_sentence = ' '.join([idx_to_word[i] for i in generated_sentence])\n",
        "print(generated_sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viMk0DxrLsRi"
      },
      "outputs": [],
      "source": [
        "model.save('shakespeare_final.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "VESCmNeiRe77"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKRxVVxAQZ5a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello wrold\n"
          ]
        }
      ],
      "source": [
        "print(\"hello wrold\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWImUXbNQfJL"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "model_name = \"google/flan-t5-xl\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_name,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16, #rank\n",
        "    lora_alpha=32, \n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_2_SEQ_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raRX4F0xQipb"
      },
      "outputs": [],
      "source": [
        "raw_dataset = load_dataset(\"Hritshhh/T5-Dataset\", split=\"train[:100%]\")\n",
        "raw_dataset = raw_dataset.train_test_split(test_size=0.1, seed=42)\n",
        "train_dataset = raw_dataset[\"train\"]\n",
        "eval_dataset = raw_dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CQPL3UCQl43"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = [\"grammar correction: \" + inp for inp in examples[\"sentence\"]]\n",
        "    targets = examples[\"corrections\"]  # already corrected sentences\n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=128, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_eval_dataset = eval_dataset.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHSVyLzmQor8"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjQ3CJBP-2tv"
      },
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    return {\"sacrebleu\": result[\"score\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JCKxNAN-6Eg"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./t5_grammar_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=3e-4,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    num_train_epochs=3,\n",
        "    predict_with_generate=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVBRU0-7--az"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_eval_dataset, \n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah1aU1S-_BXM"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = model.merge_and_unload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtuxSzGe_DmJ"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"C:\\Sarayu\\T5 Grammarator\\Fine Tuning\")\n",
        "tokenizer.save_pretrained(\"C:\\Sarayu\\T5 Grammarator\\Fine Tuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IefeGt81_HKb"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "grammar_pipe = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model= \"google/flan-t5-xl\",\n",
        "    tokenizer=tokenizer,\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "test_sentence = \"She no went to school yesterday\"\n",
        "print(grammar_pipe(f\"grammar correction: {test_sentence}\")[0][\"generated_text\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.13.6)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
